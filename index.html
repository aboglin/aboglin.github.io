---
layout: default
title: Ceara Byrne
---

<link rel="stylesheet" href="{{ "/assets/css/index.css" | relative_url }}">

<section class="about-container">
  <div class="about-image animate-on-scroll-left">
    <img src="{{ "/assets/img/Ceara_Byrne_0004.jpg" | relative_url }}" alt="Ceara Byrne">
  </div>
  <div class="about-text animate-on-scroll-right">
    <h1 style="font-family: var(--font-heading); font-size: var(--text-4xl); font-weight: var(--font-bold); margin-bottom: 1rem; color: var(--color-text); letter-spacing: -0.02em;">Dr. Ceara Byrne</h1>
    <p style="font-size: var(--text-lg); font-weight: var(--font-normal); line-height: 1.7; margin-bottom: 1.5rem; color: var(--color-text-secondary); letter-spacing: -0.01em;">Specializing in adaptive human-animal interfaces and ingestible biosensors, I engineer real-time systems that decode latent physiological and behavioral states using cutting-edge tools like machine learning, computer vision, and ultra-low-power embedded design.</p>
    <div style="display: flex; gap: 1rem; flex-wrap: wrap; margin-top: 2rem;">
      <a href="#biobehavior-section" class="research-tag biobehavior-tag" style="background: var(--color-success); color: white; padding: 0.5rem 1rem; border-radius: 8px; font-size: var(--text-sm); font-weight: var(--font-medium); text-decoration: none; transition: all 0.2s ease; box-shadow: 0 2px 8px rgba(16, 185, 129, 0.2);">üß† Biobehavioral Analysis</a>
      <a href="#ingestibles-section" class="research-tag ingestibles-tag" style="background: var(--color-accent); color: white; padding: 0.5rem 1rem; border-radius: 8px; font-size: var(--text-sm); font-weight: var(--font-medium); text-decoration: none; transition: all 0.2s ease; box-shadow: 0 2px 8px rgba(5, 150, 105, 0.2);">üíä Ingestible Devices</a>
      <a href="#wearable-section" class="research-tag wearable-tag" style="background: var(--color-info); color: white; padding: 0.5rem 1rem; border-radius: 8px; font-size: var(--text-sm); font-weight: var(--font-medium); text-decoration: none; transition: all 0.2s ease; box-shadow: 0 2px 8px rgba(14, 165, 233, 0.2);">‚åö Wearable Computing</a>
      <a href="#aci-section" class="research-tag aci-tag" style="background: var(--color-highlight); color: white; padding: 0.5rem 1rem; border-radius: 8px; font-size: var(--text-sm); font-weight: var(--font-medium); text-decoration: none; transition: all 0.2s ease; box-shadow: 0 2px 8px rgba(220, 38, 38, 0.2);">üêï Animal-Computer Interaction</a>
    </div>
  </div>
</section>

<div class="spacer"></div>

<section class="research-container">
  <h1 style="text-align: center; font-family: var(--font-heading); font-size: var(--text-5xl); font-weight: var(--font-bold); margin-bottom: 3rem; color: var(--color-text); letter-spacing: -0.02em; position: relative; z-index: 2;">üî¨ Research</h1>

  <section id="biobehavior-section" class="research-item section-biobehavior animate-on-scroll">
    <h2>üß† Biobehavior</h2>
    <div class="research-item-summary">
      <p>My research develops technology-driven methods to objectively assess behavior and suitablity, using sensors and computer vision to improve welfare, efficiency, and selection processes across species.</p>
      <button class="toggle-button" data-target="biobehavior-details">
        <span class="button-text">Learn More</span>
        <span class="button-icon">‚ñº</span>
      </button>
    </div>
    <div class="research-item-details" id="biobehavior-details">
      <p>My research develops technology-driven methods to objectively assess behavior and suitablity, using sensors and computer vision to improve welfare, efficiency, and selection processes across species. My work has integrated biobehavioral analysis and engineering to objectively identify job suitability in working dogs, which leverages sensor-equipped toys to quantify interaction patterns. By measuring behaviors such as bite duration and frequency, this approach uncovers data-driven indicators of temperament and aptitude that improve selection processes for service roles. Such methodologies move beyond subjective assessment, bridging animal needs and technological solutions to support more efficient, ethical, and transparent working dog placement. In parallel, I employ computer vision to monitor swine behaviors before, during, and after the use of ingestible devices, quantifying behavioral changes to rigorously assess device impact, such as satiety modulation from vibrating capsules‚Äîbridging animal needs and technological solutions across species.</p>
      <p><b>Why is it important?</b></p>
      <p class="important-note">Biobehavior is essential because it helps reveal how biological processes, such as genetics, hormones, and neural activity, interact with behavior to shape both health and disease in humans and animals. This research provides insights into the causes of mental and physical disorders, improves early diagnosis, and enables the development of targeted interventions and treatments. By understanding and modeling biobehavioral patterns, scientists can also predict outcomes, optimize care strategies, and design technologies that adapt to an individual's biological and behavioral needs across clinical, veterinary, and research settings.</p>
      <p><b>Relevant Publications:</b></p>
      <ul>
        <li> <b><em>Byrne, C.</em></b>, Zuerndorfer, J., Freil, L., Han, X., Sirolly, A., Gilliland, S., Starner, T., & Jackson, M. (2018). Predicting the Suitability of Service Animals Using Instrumented Dog Toys. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 1(4), 127.</li>
        <li> <b><em>Byrne, C.</em></b>, Starner, T., & Jackson, M. (2022). Quantifying canine interactions with smart toys assesses suitability for service dog work. Frontiers in Veterinary Science, 9, 886941.</li>
        <li> Srinivasan, S,. Alshareef, A., Hwang, A,. <b><em>Byrne, C.</em></b>, Kuosmann, J., Ishida, K., Jenkins, J., Liu, S., Madani, W., Hayward, A., Fabian, N., Traverso, G.  (2023). A vibrating ingestible bioelectronic stimulator modulates gastric stretch receptors for illusory satiety. Science Advances, 9(51), eadj3003.</li>
      </ul>
      <button class="toggle-button" data-target="biobehavior-details">
        <span class="button-text">Show Less</span>
        <span class="button-icon">‚ñ≤</span>
      </button>
    </div>
  </section>

  <section id="ingestibles-section" class="research-item section-ingestibles animate-on-scroll">
    <h2>üíä Ingestible and Implantable Devices</h2>
    <div class="research-item-summary">
      <p>I engineer ingestible and implantable devices for probing the gut-brain axis. This work requires integrating miniaturized sensors, stimulators, and wireless communication modules into biocompatible platforms that can withstand the harsh gastrointestinal environment.</p>
      <button class="toggle-button" data-target="ingestibles-details">
        <span class="button-text">Learn More</span>
        <span class="button-icon">‚ñº</span>
      </button>
    </div>
    <div class="research-item-details" id="ingestibles-details">
      <p>I engineer ingestible and implantable devices for probing the gut-brain axis. This work requires integrating miniaturized sensors, stimulators, and wireless communication modules into biocompatible platforms that can withstand the harsh gastrointestinal environment. My work has incorporated multimodal sensing, such as motility or physiological signals. It has focused on delivering targeted neuromodulation through electrical or mechanostimulatory actuation to modulate enteric neural activity. Implantable systems, particularly those interfacing with the enteric nervous system, must achieve stable, low-noise signal acquisition while minimizing tissue irritation and ensuring long-term reliability. Coupling these peripheral devices with electrophysiological monitoring of brain signals, such as cortical or vagal recordings, enables bidirectional feedback loops that capture correlations between gut events and central neural responses. Advanced computational pipelines, including real-time signal processing, feature extraction, and closed-loop control algorithms, allow these systems to dynamically adjust stimulation parameters based on detected neural or behavioral states. Together, this convergence of biomedical engineering and neurogastroenterology provides a pathway to mechanistically decode gut-brain communication and design targeted interventions for disorders like irritable bowel syndrome, obesity, and functional dyspepsia.</p>
      <p><b>Why is it important?</b></p>
      <p class="important-note">This convergence of biomedical engineering and neurogastroenterology provides a pathway to mechanistically decode gut-brain communication and design targeted interventions for disorders like irritable bowel syndrome, obesity, and functional dyspepsia. This work matters because it enables precise, objective insights into the complex communication between the gut and brain, ultimately uncovering how gastrointestinal activity influences neural function and health, improving patient outcomes through personalized and mechanistically-informed interventions.</p>
      <p><b>Relevant Publications:</b></p>
      <ul>
        <li>McRae, J., Jaffe, E., Ballinger, I., Gierlach, A., <b><em>Byrne, C.</em></b>, Lowell, A., Ford, R., Martinet, V., Nguyen, T., Levering, V., Kang, Z., Herrera, S., Jenkins, J., Pettinari, A., Guevara, A., Fabian, N., Hayward, A., Laken, S., Jimenez, M., Traverso, G. Ingestible Ultralong Gastric Residency Platform with Wirelessly-Triggered Disassembly for Continuous Monitoring. Science Translational Medicine. (Under Review).</li>
        <li>Srinivasan, S,. Alshareef, A., Hwang, A,. <b><em>Byrne, C.</em></b>, Kuosmann, J., Ishida, K., Jenkins, J., Liu, S., Madani, W., Hayward, A., Fabian, N., Traverso, G.  (2023). A vibrating ingestible bioelectronic stimulator modulates gastric stretch receptors for illusory satiety. Science Advances, 9(51), eadj3003.</li>
      </ul>
      <button class="toggle-button" data-target="ingestibles-details">
        <span class="button-text">Show Less</span>
        <span class="button-icon">‚ñ≤</span>
      </button>
    </div>
  </section>

  <section id="wearable-section" class="research-item section-wearable animate-on-scroll">
    <h2>‚åö Wearable Computing</h2>
    <div class="research-item-summary">
      <p>My research also sits at the intersection of user-centered design, behavioral analysis, and wearable technology, advancing both human-device and animal-computer interaction.</p>
      <button class="toggle-button" data-target="wearable-details">
        <span class="button-text">Learn More</span>
        <span class="button-icon">‚ñº</span>
      </button>
    </div>
    <div class="research-item-details" id="wearable-details">
      <p>My research also sits at the intersection of user-centered design, behavioral analysis, and wearable technology, advancing both human-device and animal-computer interaction. From developing tactile and two-way communication systems for working dogs to designing user-informed eTextile rehabilitation devices, a core theme is the creation of accessible, embedded systems that enable nonverbal, bidirectional communication and are evaluated through robust behavioral and user-focused methods. This translational approach bridges laboratory innovation and practical deployment, ensuring that both animal and human end users are meaningfully integrated into the technological design process.</p>
      <p><b>Why is it important?</b></p>
      <p class="important-note">Wearable computing is important because it enables real-time, continuous monitoring of physiological, behavioral, and environmental data, providing valuable insights that can improve health, safety, and quality of life. Wearable devices empower early detection of diseases, personalized interventions, and proactive healthcare by capturing data outside traditional clinical settings. Additionally, research in wearable computing advances the development of adaptive technologies for rehabilitation, sports performance, animal monitoring, and workplace safety, supporting both individual and population-level outcomes.</p>
      <p><b>Relevant Publications:</b></p>
      <ul>
        <li><b><em>Byrne, C.</em></b>*, Li, J.*, Liang, J.*, Lee, S., Kronborg Lyhne, M., Meng, A., Ling, S., Shiyi Li, Lopes, A., Khosravi, P., Cotter, C.,  Su, Y., Fels, J., Coffey, J.W., Hayward, A., Vegge, A., Rahbek, U., Buckley, S., Langer, R., Traverso, G.. (2025) Kinetics of Hypoglycemia in Diabetes Patients Informs Development of New Modes of Glucagon Therapy. (In Submission).</li>
        <li><b><em>Byrne, C.</em></b>, Freil, L., Starner, T., & Jackson, M. M. (2017). A method to evaluate haptic interfaces for working dogs. International Journal of Human-Computer Studies, 98, 196-207.</li>
        <li><b><em>Byrne, C.</em></b>, Kerwin, R., Zuerndorfer, J., Gilliland, S., Guo, Z., Jackson, M., & Starner, T. E. (2014). Two-way communication between working dogs and their handlers. IEEE Pervasive Computing, 13(2), 80-83.</li>
      </ul>
      <button class="toggle-button" data-target="wearable-details">
        <span class="button-text">Show Less</span>
        <span class="button-icon">‚ñ≤</span>
      </button>
    </div>
  </section>


  <section id="aci-section" class="research-item section-aci animate-on-scroll">
    <h2>üêï Building out the Field of Animal-Computer Interaction</h2>
    <div class="research-item-summary">
      <p>My research builds out the emerging field of Animal-Computer Interaction by leveraging advances from biomedical engineering, veterinary science, animal behavior, and computer science to engineer technologies that support meaningful multispecies integration</p>
      <button class="toggle-button" data-target="aci-details">
        <span class="button-text">Learn More</span>
        <span class="button-icon">‚ñº</span>
      </button>
    </div>
    <div class="research-item-details" id="aci-details">
      <p>My research builds out the emerging field of Animal-Computer Interaction by leveraging advances from biomedical engineering, veterinary science, animal behavior, and computer science to engineer technologies that support meaningful multispecies integration. Through the development of sensing systems, ingestible devices, and interactive environments, I create new tools and frameworks that enable richer communication and data sharing between humans and animals in diverse contexts, from farming and laboratory research to home and clinical care. This work aims to forge deeper, bidirectional relationships, advancing our understanding of animal agency while expanding the possibilities for multispecies collaboration and shared experiences.</p>
      <p><b>Why is it important?</b></p>
      <p class="important-note">Animal-Computer Interaction unlocks novel opportunities for multispecies research, enables the ethical integration of animals as active participants in science, and offers powerful new tools for both basic and applied investigation. By adopting technologies that foster richer communication and agency for animals, institutions can broaden their impact in fields like biomedical engineering, behavioral science, agriculture, and collaborative technology design‚Äîopening doors to discoveries that would be impossible through human-centered research alone. Furthermore, this approach aligns with growing societal and regulatory interest in animal welfare and interspecies ethics, positioning a research institution as a leader at the frontier of responsible, innovative research.</p>
      <p><b>Relevant Publications:</b></p>
      <ul>
        <li><b><em>Byrne, C.</em></b> Engaging Non-Human Species in Using Technologies: Strategies for Acclimation, Training, and Autonomous Use of Technology. Computing Technology, Animal Welfare and Human-Animal Relations. (Under review).</li>
        <li><b><em>Byrne, C.</em></b>, & Logas, J. (2021). The future of technology and computers in veterinary medicine. Diagnostics and Therapy in Veterinary Dermatology, 245-250.</li>
        <li>Freil, L., <b><em>Byrne, C.</em></b>, Valentin, G., Zeagler, C., Roberts, D., Starner, T., & Jackson, M. (2017). Canine-Centered Computing. Foundations and Trends¬Æ in Human-Computer Interaction, 10(2), 87-164.</li>
      </ul>
      <button class="toggle-button" data-target="aci-details">
        <span class="button-text">Show Less</span>
        <span class="button-icon">‚ñ≤</span>
      </button>
    </div>
  </section>
</section>

<div class="spacer"></div>

<section class="teaching-container animate-on-scroll">
  <h1 style="text-align: center; font-family: var(--font-heading); font-size: var(--text-4xl); font-weight: var(--font-bold); margin-bottom: 2rem; color: var(--color-text); letter-spacing: -0.02em;">üéì Teaching</h1>
  <p>My background in computer science (CS), human computer interaction (HCI), and industrial design (ID) has shaped my teaching and advising philosophy in three critical ways. A fundamental element in design is the ability to effectively and constructively critique work in a way that enables students to take action on their projects and their work. Secondly, Georgia Tech's HCI program has taught me how to "fail early, fail often, fail intelligently," ensuring that you fail in a way that cultivates adaptation and innovation. In other words, small, strategic proof-of-concepts go a long way to help make a project successful. Lastly, bridging the two fields of CS and design has taught me the importance of grounding difficult concepts to accessible topics for reflection. Asking questions, such as "how does data collection impact design?" or "would a spectrogram be a better representation for this data?" allow students to understand how each part of the process fits within the whole.</p>

  <p>I have been the instructor-on-record for three undergraduate human-computer interaction courses and, notably, one of those classes was conducted during the academic year at the beginning of the COVID pandemic (Spring 2020). Additionally, I have been a teaching assistant in several courses on mobile and ubiquitous computing, on human-computer interaction, and on design while at Georgia Tech.</p>
</section>

<div class="spacer"></div>

<section class="mentorship-container animate-on-scroll">
  <h1 style="text-align: center; font-family: var(--font-heading); font-size: var(--text-4xl); font-weight: var(--font-bold); margin-bottom: 2rem; color: var(--color-text); letter-spacing: -0.02em;">ü§ù Mentorship</h1>
  <p>One priority of my postdoctoral fellowship has been to be a more effective mentor. During the past two years, I have mentored 6 students across varying levels of academic expertise, from undergraduate to PhD. As a mentor, my goal is to not only effectively direct those in my charge, but also ensure they have the skills and confidence to accomplish their own goals in the future. My advising approach has increasingly turned to ‚Äúteach people how to fail with recovery in mind‚Äù, or ‚Äúfail early, fail often, fail intelligently‚Äù. Failure is okay and expected. How and how quickly one recovers from failure is what makes an effective researcher. Designing experiments to productively allow one to reflect on outcomes and pivot correctly is important. I find that mentoring is more about helping others be successful than providing them with the clearest way forward. Sometimes that can mean taking a step back and letting the students work things out for themselves, while for others it means being in the trenches and supporting them every step of the way. Mentoring requires the humility to know that there isn't one right path.</p>

  <p>My mentees have gone on to a variety of professions. Many work in industry, however, notably several have continued within academia. Three have continued beyond their undergraduate degrees to complete their Masters degrees at Northeastern University, University of Washington, and Harvard University. Two have continued to PhD, one studying nanorobotics at EPFL and the other in bioengineering at UC Berkeley-UCSF.</p>
</section>

<div class="spacer"></div>

<section class="service-container animate-on-scroll">
  <h1 style="text-align: center; font-family: var(--font-heading); font-size: var(--text-4xl); font-weight: var(--font-bold); margin-bottom: 2rem; color: var(--color-text); letter-spacing: -0.02em;">üåü Relevant Service</h1>
  <p>From 2023 to 2025, I served on the steering committee for the International Conference on Animal-Computer Interaction, helping to guide the strategic direction of this interdisciplinary community and ensure the conference's continued impact and growth. During this time, I took on major leadership roles, acting as program co-chair for the 2023 and 2024 conferences, where I coordinated the review process, curated the technical program, and supported high-quality scholarship. Most recently, in 2025, I am serving as Emerging Work Program co-chair, leading the integration of novel and cross-cutting research into the ACI field.</p>
</section>

<!-- Floating Action Button -->
<div id="floating-action" style="position: fixed; bottom: 2rem; right: 2rem; z-index: 1000; opacity: 0; transform: translateY(100px); transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);">
  <button onclick="scrollToTop()" style="background: var(--color-primary); color: white; border: none; width: 60px; height: 60px; border-radius: 50%; box-shadow: 0 4px 16px rgba(37, 99, 235, 0.3); cursor: pointer; display: flex; align-items: center; justify-content: center; font-size: 1.5rem; transition: all 0.2s ease;">
    ‚Üë
  </button>
</div>

<!-- Progress Bar -->
<div id="progress-bar" style="position: fixed; top: 0; left: 0; width: 0%; height: 3px; background: var(--color-primary); z-index: 1001; transition: width 0.3s ease;"></div>

<script>
document.addEventListener('DOMContentLoaded', function() {
  // Scroll-triggered animations with proper ordering
  const observerOptions = {
    threshold: 0.1,
    rootMargin: '0px 0px -50px 0px'
  };

  const observer = new IntersectionObserver((entries) => {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        // Add a small delay based on section order to ensure proper sequence
        const sectionId = entry.target.id;
        let delay = 0;

        switch(sectionId) {
          case 'biobehavior-section': delay = 100; break;
          case 'ingestibles-section': delay = 200; break;
          case 'wearable-section': delay = 300; break;
          case 'aci-section': delay = 400; break;
        }

        setTimeout(() => {
          entry.target.classList.add('animated');
        }, delay);
      }
    });
  }, observerOptions);

  // Observe all elements with animation classes
  document.querySelectorAll('.animate-on-scroll, .animate-on-scroll-left, .animate-on-scroll-right').forEach(el => {
    observer.observe(el);
  });

  // Progress bar and floating action button
  const progressBar = document.getElementById('progress-bar');
  const floatingAction = document.getElementById('floating-action');

  window.addEventListener('scroll', () => {
    const scrollTop = window.pageYOffset;
    const docHeight = document.body.offsetHeight - window.innerHeight;
    const scrollPercent = (scrollTop / docHeight) * 100;

    progressBar.style.width = scrollPercent + '%';

    if (scrollTop > 300) {
      floatingAction.style.opacity = '1';
      floatingAction.style.transform = 'translateY(0)';
    } else {
      floatingAction.style.opacity = '0';
      floatingAction.style.transform = 'translateY(100px)';
    }
  });

  // Initialize all research items to show only summary
  const researchItems = document.querySelectorAll('.research-item');
  researchItems.forEach(item => {
    const details = item.querySelector('.research-item-details');
    const summary = item.querySelector('.research-item-summary');

    // Hide details initially
    details.style.display = 'none';
    details.style.opacity = '0';
    details.style.transform = 'translateY(-10px)';
    details.style.transition = 'all 0.3s ease-in-out';

    // Show summary initially
    summary.style.display = 'block';
    summary.style.opacity = '1';
    summary.style.transform = 'translateY(0)';
    summary.style.transition = 'all 0.3s ease-in-out';
  });

  // Add click event listeners to all toggle buttons
  const toggleButtons = document.querySelectorAll('.toggle-button');
  toggleButtons.forEach(button => {
    button.addEventListener('click', function() {
      const targetId = this.getAttribute('data-target');
      const targetDetails = document.getElementById(targetId);
      const parentItem = this.closest('.research-item');
      const summary = parentItem.querySelector('.research-item-summary');
      const details = parentItem.querySelector('.research-item-details');

      // Find both buttons in this research item
      const summaryButton = summary.querySelector('.toggle-button');
      const detailsButton = details.querySelector('.toggle-button');
      const summaryButtonText = summaryButton.querySelector('.button-text');
      const summaryButtonIcon = summaryButton.querySelector('.button-icon');
      const detailsButtonText = detailsButton.querySelector('.button-text');
      const detailsButtonIcon = detailsButton.querySelector('.button-icon');

      if (targetDetails.style.display === 'none' || targetDetails.style.display === '') {
        // Show details
        summary.style.opacity = '0';
        summary.style.transform = 'translateY(-10px)';

        setTimeout(() => {
          summary.style.display = 'none';
          details.style.display = 'block';
          details.style.opacity = '1';
          details.style.transform = 'translateY(0)';
        }, 150);

        // Update both buttons to "Show Less" state
        summaryButtonText.textContent = 'Show Less';
        summaryButtonIcon.textContent = '‚ñ≤';
        detailsButtonText.textContent = 'Show Less';
        detailsButtonIcon.textContent = '‚ñ≤';
      } else {
        // Show summary
        details.style.opacity = '0';
        details.style.transform = 'translateY(-10px)';

        setTimeout(() => {
          details.style.display = 'none';
          summary.style.display = 'block';
          summary.style.opacity = '1';
          summary.style.transform = 'translateY(0)';
        }, 150);

        // Update both buttons to "Learn More" state
        summaryButtonText.textContent = 'Learn More';
        summaryButtonIcon.textContent = '‚ñº';
        detailsButtonText.textContent = 'Learn More';
        detailsButtonIcon.textContent = '‚ñº';
      }
    });
  });
});

// Scroll to top function
function scrollToTop() {
  window.scrollTo({
    top: 0,
    behavior: 'smooth'
  });
}

// Add some particle effects
function createParticles() {
  const particleCount = 50;
  const container = document.body;

  for (let i = 0; i < particleCount; i++) {
    const particle = document.createElement('div');
    particle.style.position = 'fixed';
    particle.style.width = '2px';
    particle.style.height = '2px';
    particle.style.background = `hsl(${Math.random() * 60 + 180}, 70%, 60%)`;
    particle.style.borderRadius = '50%';
    particle.style.pointerEvents = 'none';
    particle.style.zIndex = '1';
    particle.style.left = Math.random() * 100 + '%';
    particle.style.top = Math.random() * 100 + '%';
    particle.style.animation = `floatParticle ${Math.random() * 10 + 10}s linear infinite`;

    container.appendChild(particle);

    // Remove particle after animation
    setTimeout(() => {
      if (particle.parentNode) {
        particle.parentNode.removeChild(particle);
      }
    }, (Math.random() * 10 + 10) * 1000);
  }
}

  // Create particles periodically
setInterval(createParticles, 3000);

// Enhanced smooth scrolling for research tags
document.querySelectorAll('.research-tag').forEach(tag => {
  tag.addEventListener('click', function(e) {
    e.preventDefault();
    const targetId = this.getAttribute('href').substring(1);
    const targetElement = document.getElementById(targetId);

    if (targetElement) {
      // Add a highlight effect to the target section
      targetElement.style.transform = 'scale(1.02)';
      targetElement.style.boxShadow = '0 20px 40px rgba(0, 212, 170, 0.4)';

      // Use scrollIntoView with proper options
      targetElement.scrollIntoView({
        behavior: 'smooth',
        block: 'start',
        inline: 'nearest'
      });

      // Remove highlight effect after animation
      setTimeout(() => {
        targetElement.style.transform = '';
        targetElement.style.boxShadow = '';
      }, 2000);
    }
  });
});
</script>
